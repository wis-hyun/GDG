{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW08JFT0BUk1"
      },
      "source": [
        "# 컨볼루션 신경망(Convolution Neural Networks, CNN)\n",
        "\n",
        "- 완전 연결 네트워크의 문제점으로부터 시작\n",
        "\n",
        "  - 매개변수의 폭발적인 증가\n",
        "\n",
        "  - 공간 추론의 부족\n",
        "    - 픽셀 사이의 근접성 개념이 완전 연결 계층(Fully-Connected Layer)에서는 손실됨\n",
        "\n",
        "- 합성곱 계층은 입력 이미지가 커져도 튜닝해야 할 매개변수 개수에 영향을 주지 않음\n",
        "\n",
        "- 또한 그 어떠한 이미지에도 **그 차원 수와 상관없이** 적용될 수 있음\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n",
        "  \n",
        "  <center>[LeNet-5 구조]</center>\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORxbya83GHwc"
      },
      "source": [
        "## 컨볼루션 연산 (Convolution Operation)\n",
        "\n",
        "- 필터(filter) 연산\n",
        "  - 입력 데이터에 필터를 통한 어떠한 연산을 진행\n",
        "  \n",
        "  - **필터에 대응하는 원소끼리 곱하고, 그 합을 구함**\n",
        "\n",
        "  - 연산이 완료된 결과 데이터를 **특징 맵(feature map)**이라 부름\n",
        "\n",
        "- 필터(filter)\n",
        "  - 커널(kernel)이라고도 칭함\n",
        "  \n",
        "  - 흔히 사진 어플에서 사용하는 '이미지 필터'와 비슷한 개념\n",
        "\n",
        "  - 필터의 사이즈는 \"거의 항상 홀수\"\n",
        "    - 짝수이면 패딩이 비대칭이 되어버림\n",
        "  \n",
        "    - 왼쪽, 오른쪽을 다르게 주어야함\n",
        "  \n",
        "    - 중심위치가 존재, 즉 구별된 하나의 픽셀(중심 픽셀)이 존재\n",
        "\n",
        "  - 필터의 학습 파라미터 개수는 입력 데이터의 크기와 상관없이 일정  \n",
        "    따라서, 과적합을 방지할 수 있음\n",
        "\n",
        "  <br>\n",
        "  \n",
        "  <img src=\"http://deeplearning.net/software/theano_versions/dev/_images/numerical_no_padding_no_strides.gif\">\n",
        "\n",
        "  <sub>[이미지 출처] http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html</sub>\n",
        "\n",
        "  <br>\n",
        "\n",
        "- 연산 시각화\n",
        "  <img src=\"https://www.researchgate.net/profile/Ihab_S_Mohamed/publication/324165524/figure/fig3/AS:611103423860736@1522709818959/An-example-of-convolution-operation-in-2D-2.png\" width=\"500\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.researchgate.net/figure/An-example-of-convolution-operation-in-2D-2_fig3_324165524</sub>\n",
        "\n",
        "\n",
        "- 일반적으로, 합성곱 연산을 한 후의 데이터 사이즈는  \n",
        "  ### $\\quad (n-f+1) \\times (n-f+1)$\n",
        "    $n$: 입력 데이터의 크기  \n",
        "    $f$: 필터(커널)의 크기\n",
        "\n",
        "  <br>\n",
        "  \n",
        "  <img src=\"https://miro.medium.com/max/1400/1*Fw-ehcNBR9byHtho-Rxbtw.gif\" width=\"400\">\n",
        "\n",
        "  위 예에서 입력 데이터 크기($n$)는 5, 필터의 크기($k$)는 3이므로  \n",
        "  출력 데이터의 크기는 $(5 - 3 + 1) = 3$\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <sub>[이미지 출처] https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-60rJIUG49O"
      },
      "source": [
        "## Convolution vs Cross Correlation (참고)\n",
        "\n",
        "- 실제로 머신러닝 분야에서 '합성곱'이라는 용어를 일반적으로 사용하고는 있지만  \n",
        "  여기서 말하는 합성곱 연산은 '수학적 용어'로는 **교차 상관 관계(cross-correlation)**이라고 볼 수 있음\n",
        "\n",
        "- 수학적으로 합성곱 연산은 필터를 '뒤집어서' 연산을 진행\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Comparison_convolution_correlation.svg/400px-Comparison_convolution_correlation.svg.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://en.wikipedia.org/wiki/Convolution</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-ekDsJwN2Y-"
      },
      "source": [
        "## 패딩(padding)과 스트라이드(stride)\n",
        "- 필터(커널) 사이즈과 함께 **입력 이미지와 출력 이미지의 사이즈를 결정**하기 위해 사용\n",
        "\n",
        "- 사용자가 결정할 수 있음\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNisiLu2TY9z"
      },
      "source": [
        "\n",
        "### 패딩\n",
        "- 입력 데이터의 주변을 특정 값으로 채우는 기법\n",
        "  - 주로 0으로 많이 채움\n",
        "\n",
        "  <img src=\"http://deeplearning.net/software/theano_versions/dev/_images/arbitrary_padding_no_strides.gif\" width=\"300\">\n",
        "\n",
        "  <sub>[이미지 출처] https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1</sub>\n",
        "\n",
        "<br>\n",
        "\n",
        "- 출력 데이터의 크기\n",
        "  ### $\\quad (n+2p-f+1) \\times (n+2p-f+1)$\n",
        "  <br>\n",
        "\n",
        "  위 그림에서, 입력 데이터의 크기($n$)는 5, 필터의 크기($f$)는 3, 패딩값($p$)은 1이므로    \n",
        "  출력 데이터의 크기는 ($5 + 2\\times 2 - 4 + 1) = 6$\n",
        "\n",
        "<br>\n",
        "\n",
        "### 'valid' 와 'same'\n",
        "- 'valid'\n",
        "  - 패딩을 주지 않음\n",
        "  - padding=0\n",
        "    - 0으로 채워진 테두리가 아니라 패딩을 주지 않는다는 뜻!\n",
        "\n",
        "- 'same'\n",
        "  - 패딩을 주어 입력 이미지의 크기와 연산 후의 이미지 크기를 같게!\n",
        "\n",
        "  - 만약, 필터(커널)의 크기가 $k$ 이면,  \n",
        "    패딩의 크기는 $p = \\frac{k-1}{2}$ (단, <u>stride=1)</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlZ7zG6ON85J"
      },
      "source": [
        "\n",
        "\n",
        "### 스트라이드\n",
        "- 필터를 적용하는 간격을 의미\n",
        "\n",
        "- 아래는 그림의 간격 2\n",
        "\n",
        "  <img src=\"http://deeplearning.net/software/theano_versions/dev/_images/no_padding_strides.gif\">\n",
        "\n",
        "  <sub>[이미지 출처] https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1</sub>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPcsND-0OCNm"
      },
      "source": [
        "## 출력 데이터의 크기\n",
        "\n",
        "## $\\qquad OH = \\frac{H + 2P - FH}{S} + 1 $\n",
        "## $\\qquad OW = \\frac{W + 2P - FW}{S} + 1 $\n",
        "\n",
        "- 입력 크기 : $(H, W)$\n",
        "\n",
        "- 필터 크기 : $(FH, FW)$\n",
        "\n",
        "- 출력 크기 : $(OH, OW)$\n",
        "\n",
        "- 패딩, 스트라이드 : $P, S$\n",
        "\n",
        "- (주의)\n",
        "  - 위 식의 값에서 $\\frac{H + 2P - FH}{S}$ 또는 $\\frac{W + 2P - FW}{S}$가 정수로 나누어 떨어지는 값이어야 한다.  \n",
        "  - 만약, 정수로 나누어 떨어지지 않으면  \n",
        "    패딩, 스트라이드값을 조정하여 정수로 나누어 떨어지게 해야!\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUeddu9eJ6fG"
      },
      "source": [
        "## 텐서플로우/케라스 메소드\n",
        "- 이미지 합성곱의 경우 기본적으로 저차원 API의 `tf.nn.conv2d()`를 사용\n",
        "  - `input` : 형상이 $(B, \\ H, \\ W, \\ D)$인 입력 이미지 배치\n",
        "\n",
        "  - `filter` : $N$개의 필터가 쌓여 형상이 $(k_H, \\ k_W, \\ D, \\ N)$ 인 텐서\n",
        "\n",
        "  - `strides` : 보폭을 나타내는 4개의 정수 리스트.  \n",
        "    $\\qquad \\qquad [1, \\ S_H, \\ S_W, \\ 1]$ 을 사용\n",
        "\n",
        "  - `padding` : 패딩을 나타내는 4x2개의 정수 리스트나 사전 정의된 패딩 중 무엇을 사용할지 정의  \n",
        "    \"VALID\" or \"SAME\" 문자열 사용\n",
        "\n",
        "  - `name` : 해당 연산을 식별하는 이름\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1-KCMignLPKb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy version: 1.23.5\n",
            "Pandas version: 1.5.3\n",
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"Numpy version:\", np.__version__)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Keras 사용 예시\n",
        "glorot_initializer = tf.keras.initializers.GlorotUniform()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uwyx2BfQOh2E"
      },
      "outputs": [],
      "source": [
        "k, D, N = (3, 16, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dS16AOrlJq3d"
      },
      "outputs": [],
      "source": [
        "kernel_size = [k, k, D, N]\n",
        "glorot_uni_initializer = tf.initializers.GlorotUniform()\n",
        "\n",
        "kernels = tf.Variable(glorot_uni_initializer(kernel_size),\n",
        "                      trainable=True, name=\"filters\")\n",
        "\n",
        "bias = tf.Variable(tf.zeros(shape=[N]), trainable=True, name='bias')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nU_8EyHbJqyM"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def conv_layer(x, kernels, bias, s):\n",
        "    z = tf.nn.conf2d(x, kernels, strides=[1, s, s, 1], padding='VALID')\n",
        "    return tt.nn.relu(z + bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlJ9VEL8MZI8"
      },
      "source": [
        "### 간단한 합성곱 신경망 구성 (저차원 API)\n",
        "\n",
        "- 저차원 API 사용\n",
        "\n",
        "- 표현이 명확하다는 장점"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pbBP4D-JMR6E"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_kerenls=32, kernel_size=(3,3), stride=1):\n",
        "        super().__init__()\n",
        "        self.num_kernels = num_kernels\n",
        "        self.kernel_size = kernels_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_channels = input_shape[-1]\n",
        "        kernels_shape = (*self.kernel_size, input_channels, self.num_kernels)\n",
        "        glorot_init = tf.initializers.GlorotUniform()\n",
        "        self.kernels = self.add_weight(\n",
        "            name='kernels', shape=kernels_shape, initializer=glorot_init, trainable=True)\n",
        "        self.bias = self.add_weight(name='bias', shape=(self.num_kernels, ),\n",
        "                                    initializer='random_normal', trainable=True)\n",
        "    def call(self, inputs):\n",
        "        return conv_layer(inputs, self.kernels, self.bias, self.stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPBFWdt_Nt6L"
      },
      "source": [
        "### 간단한 합성곱 신경망 구성 (케라스 API)\n",
        "\n",
        "- 케라스 API 사용\n",
        "\n",
        "- 일반적인 계층의 초기화 캡슐화해서 제공하기 때문에 개발속도를 높여줌\n",
        "\n",
        "  - 따라서, 고급 CNN을 구성할 때 해당 메소드 방식을 사용하는게 좋음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NlrUtCCMOFm_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "G3DVKhvrOSHO"
      },
      "outputs": [],
      "source": [
        "s = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MA4HHPJ-MR8q"
      },
      "outputs": [],
      "source": [
        "conv = Conv2D(filters=N, kernel_size=(k,k), strides=s,\n",
        "              padding='valid', activation='relu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x4UoMbF8jJ9"
      },
      "source": [
        "## 풀링(Pooling)\n",
        "\n",
        "- 필터(커널) 사이즈 내에서 특정 값을 추출하는 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDiaO3XF8oC_"
      },
      "source": [
        "### 맥스 풀링(Max Pooling)\n",
        "- 가장 많이 사용되는 방법\n",
        "\n",
        "- 출력 데이터의 사이즈 계산은 컨볼루션 연산과 동일\n",
        "## $\\quad OH = \\frac{H + 2P - FH}{S} + 1 $\n",
        "## $\\quad OW = \\frac{W + 2P - FW}{S} + 1 $\n",
        "\n",
        "- 일반적으로 stride=2, kernel_size=2 를 통해  \n",
        "  **특징맵의 크기를 <u>절반으로 줄이는 역할</u>**\n",
        "\n",
        "- 모델이 물체의 주요한 특징을 학습할 수 있도록 해주며,  \n",
        "  컨볼루션 신경망이 이동 불변성 특성을 가지게 해줌\n",
        "  - 예를 들어, 아래의 그림에서 초록색 사각형 안에 있는  \n",
        "    2와 8의 위치를 바꾼다해도 맥스 풀링 연산은 8을 추출\n",
        "\n",
        "- 모델의 파라미터 개수를 줄여주고, 연산 속도를 빠르게 해줌\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://cs231n.github.io/assets/cnn/maxpool.jpeg\" width=\"600\">\n",
        "\n",
        "  <sub>[이미지 출처] https://cs231n.github.io/convolutional-networks/</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4czHpHrW8qyb"
      },
      "source": [
        "### 평균 풀링(Avg Pooling)\n",
        "\n",
        "- 필터 내의 있는 픽셀값의 평균을 구하는 과정\n",
        "\n",
        "- 과거에 많이 사용, 요즘은 잘 사용되지 않는다.\n",
        "\n",
        "- 맥스풀링과 마찬가지로 stride=2, kernel_size=2 를 통해  \n",
        "  특징 맵의 사이즈를 줄이는 역할\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/profile/Juan_Pedro_Dominguez-Morales/publication/329885401/figure/fig21/AS:707709083062277@1545742402308/Average-pooling-example.png\" width=\"600\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.researchgate.net/figure/Average-pooling-example_fig21_329885401</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2eTsYniO79V"
      },
      "source": [
        "### 텐서플로우/케라스 메소드\n",
        "\n",
        "- `tf.nn.max_pool()` 또는 `tf.nn.avg_pool()`\n",
        "\n",
        "  - `value` : $(B, \\ H, \\ W, \\ D)$ 인 형상을 가진 입력 이미지 배치\n",
        "\n",
        "  - `ksize` : 차원별 윈도우 크기를 나타내는 4개의 정수 리스트.  \n",
        "      일반적으로 $[1, \\ k, \\ k, \\ 1]$ 사용\n",
        "\n",
        "  - `strides` : 보폭을 나타내는 4개의 정수 리스트. `tf.nn.conv2d()`와 유사\n",
        "\n",
        "  - `padding` : 패딩 알고리즘을 정의하는 문자열(\"VALID\" 또는 \"SAME\")\n",
        "\n",
        "  - `name` : 해당 연산을 식별할 이름\n",
        "\n",
        "<br>\n",
        "\n",
        "- 고수준 API 사용\n",
        "\n",
        "  - `tf.keras.layers.AvgPool2D()` 또는 `tf.keras.layers.MaxPool2D()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NL27tG0uQDAt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import AvgPool2D, MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qWw49mAzQOJa"
      },
      "outputs": [],
      "source": [
        "k, s = (3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Pe5SPo1tAP_U"
      },
      "outputs": [],
      "source": [
        "avg_pool = AvgPool2D(pool_size=k, strides=[s, s], padding='valid')\n",
        "max_pool = MaxPool2D(pool_size=k, strides=[s, s], padding='valid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmhhig5YQViL"
      },
      "source": [
        "## 완전 연결 계층(Fully-Connected Layer)\n",
        "\n",
        "- 입력으로 받은 텐서를 1차원으로 평면화(flatten) 함\n",
        "\n",
        "- 밀집 계층(Dense Layer)라고도 함\n",
        "\n",
        "- 일반적으로 분류기로서 **네트워크의 마지막 계층에서 사용**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JQ_ZMUwMQ9Zx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kUHf1gnFQSLL"
      },
      "outputs": [],
      "source": [
        "output_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9pYaCxi5Q76A"
      },
      "outputs": [],
      "source": [
        "fc = Dense(units=output_size, activation='relu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQDl4bYMSBgr"
      },
      "source": [
        "## 유효 수용 영역(ERF, Effective Receptive Field)\n",
        "\n",
        "- 입력 이미지에서 거리가 먼 요소를 상호 참조하여 결합하여 네트워크 능력에 영향을 줌\n",
        "\n",
        "- 입력 이미지의 영역을 정의해 주어진 계층을 위한 뉴런의 활성화에 영향을 미침\n",
        "\n",
        "- 한 계층의 필터 크기나 윈도우 크기로 불리기 때문에 RF(receptive field, 수용 영역)이라는 용어를 흔히 볼 수 있음\n",
        "\n",
        "  <img src=\"https://wiki.math.uwaterloo.ca/statwiki/images/8/8c/understanding_ERF_fig0.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://wiki.math.uwaterloo.ca/statwiki/index.php?title=Understanding_the_Effective_Receptive_Field_in_Deep_Convolutional_Neural_Networks</sub>\n",
        "\n",
        "<br>\n",
        "\n",
        "- RF의 중앙에 위치한 픽셀은 주변에 있는 픽셀보다 더 높은 가중치를 가짐\n",
        "  - 중앙부에 위치한 픽셀은 여러 개의 계층을 전파한 값\n",
        "\n",
        "  - 중앙부에 있는 픽셀은 주변에 위치한 픽셀보다 더 많은 정보를 가짐\n",
        "\n",
        "- 가우시안 분포를 따름\n",
        "\n",
        "  <img src=\"https://www.researchgate.net/publication/316950618/figure/fig4/AS:495826810007552@1495225731123/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.researchgate.net/figure/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks_fig4_316950618</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziTX7TwxVDIK"
      },
      "source": [
        "## CNN 구현\n",
        "\n",
        "### LeNet-5\n",
        "\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n",
        "  \n",
        "  <center>[LeNet-5 구조]</center>\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OmHHY6NoRC6P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vzO3O0sucnsA"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "MzpZgJdteQCA"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train[..., np.newaxis], x_test[..., np.newaxis]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "B5gVNNOAczaw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0, :, :, 0]) #0이면 검은색, 255이면 흰색 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "i_ZpIqPOdWcY"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tGwCK9ewcvIg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
            "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
            "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
            "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
            "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
            "  0.99215686 0.35294118 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.54509804\n",
            "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313725\n",
            "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
            "  0.09803922 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
            "  0.58823529 0.10588235 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
            "  0.99215686 0.73333333 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.97647059\n",
            "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
            "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
            "  0.98039216 0.71372549 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09411765 0.44705882\n",
            "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
            "  0.30588235 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.21568627 0.6745098\n",
            "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "  0.52156863 0.04313725 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.53333333 0.99215686\n",
            "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0, :, :, 0]) #0부터 1사이의 값으로 정규화 됨 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "_fYNdTcwdd9R"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "epochs = 100\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "rsHzPXwAdL0y"
      },
      "outputs": [],
      "source": [
        "class LeNet5(Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = Conv2D(6, kernel_size=(5,5), padding='same', activation='relu')\n",
        "        self.conv2 = Conv2D(16, kernel_size=(5,5), activation='relu')\n",
        "        self.max_pool = MaxPooling2D(pool_size=(2,2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation='relu')\n",
        "        self.dense2 = Dense(84, activation='relu')\n",
        "        self.dense3 = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, input_data):\n",
        "        x = self.max_pool(self.conv1(input_data))\n",
        "        x = self.max_pool(self.conv2(x))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense2(self.dense1(x)))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PujKmeDdaxBo"
      },
      "outputs": [],
      "source": [
        "model = LeNet5(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Vu0aJkVKb45J"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "bExFEuGSb8pP"
      },
      "outputs": [],
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
        "             tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Fsu-YN3jcGXj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.5363 - accuracy: 0.8296 - val_loss: 0.1655 - val_accuracy: 0.9482\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1333 - accuracy: 0.9587 - val_loss: 0.0994 - val_accuracy: 0.9671\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0963 - accuracy: 0.9700 - val_loss: 0.0788 - val_accuracy: 0.9748\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0774 - accuracy: 0.9757 - val_loss: 0.0729 - val_accuracy: 0.9759\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0661 - accuracy: 0.9792 - val_loss: 0.0597 - val_accuracy: 0.9796\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0575 - accuracy: 0.9822 - val_loss: 0.0544 - val_accuracy: 0.9827\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0503 - val_accuracy: 0.9837\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.0438 - val_accuracy: 0.9861\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0410 - val_accuracy: 0.9865\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0346 - accuracy: 0.9889 - val_loss: 0.0377 - val_accuracy: 0.9873\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0360 - val_accuracy: 0.9889\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.0356 - val_accuracy: 0.9875\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0331 - val_accuracy: 0.9894\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0326 - val_accuracy: 0.9898\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0382 - val_accuracy: 0.9883\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0336 - val_accuracy: 0.9895\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0347 - val_accuracy: 0.9898\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x31b3071d0>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size = batch_size,\n",
        "          epochs = epochs,\n",
        "          validation_data = (x_test, y_test),\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "tCt7WmtfcT0T"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "fwS3pwETiGPU"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-3fdb48c23fb345f0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-3fdb48c23fb345f0\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6007;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikbaQ8uuh4qc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeMPNQRYoBW6"
      },
      "source": [
        "# Visual Geometry Group Net(VGGNet)\n",
        "\n",
        "- 2014년 ILSVRC 분류 과제에서 2등을 차지했지만, 이 후의 수많은 연구에 영향을 미침\n",
        "\n",
        "- 특징\n",
        "\n",
        "  - 활성화 함수로 `ReLU` 사용, Dropout 적용\n",
        "\n",
        "  - 합성곱과 풀링 계층으로 구성된 블록과 분류를 위한 완전 연결계층으로 결합된 전형적인 구조\n",
        "\n",
        "  - 인위적으로 데이터셋을 늘림\n",
        "    \n",
        "    - 이미지 변환, 좌우 반전 등의 변환을 시도\n",
        "\n",
        "  - 몇 개의 합성곱 계층과 최대-풀링 계층이 따르는 5개의 블록과,  \n",
        "    3개의 완전연결계층(학습 시, 드롭아웃 사용)으로 구성\n",
        "\n",
        "  - 모든 합성곱과 최대-풀링 계층에 `padding='SAME'` 적용\n",
        "\n",
        "  - 합성곱 계층에는 `stride=1`, 활성화 함수로 `ReLU` 사용\n",
        "\n",
        "  - 특징 맵 깊이를 증가시킴\n",
        "\n",
        "  - 척도 변경을 통한 데이터 보강(Data Augmentation)\n",
        "\n",
        "\n",
        "\n",
        "- 기여\n",
        "\n",
        "  - 3x3 커널을 갖는 두 합성곱 계층을 쌓은 스택이 5x5 커널을 갖는 하나의 합성곱 계층과 동일한 수용영역(ERF)을 가짐\n",
        "\n",
        "  - 11x11 사이즈의 필터 크기를 가지는 AlexNet과 비교하여,  \n",
        "    더 작은 합성곱 계층을 더 많이 포함해 더 큰 ERF를 얻음\n",
        "\n",
        "  - 이와 같이 합성곱 계층의 개수가 많아지면,  \n",
        "    **매개변수 개수를 줄이고, 비선형성을 증가시킴**\n",
        "\n",
        "\n",
        "- VGG-19 아키텍쳐\n",
        "\n",
        "  - VGG-16에 3개의 합성곱 계층을 추가\n",
        "\n",
        "  <br>   \n",
        "\n",
        "  <img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\">\n",
        "  <center>VGG-16 아키텍쳐</center>\n",
        "\n",
        "  <sub>[이미지 출처] https://neurohive.io/en/popular-networks/vgg16/ </sub>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "- (참고) ILSVRC의 주요 분류 metric 중 하나는 `top-5`\n",
        "  \n",
        "  - 상위 5개 예측 안에 정확한 클래스가 포함되면 제대로 예측한 것으로 간주\n",
        "\n",
        "  - 일반적인 `top-k` metric의 특정 케이스\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDsV_T3HSlJS"
      },
      "source": [
        "## 텐서플로우 모델\n",
        "- 직접 VGG 아키텍쳐를 공식적으로 제공하지는 않지만 github에 깔끔하게 구현된 모델 존재\n",
        "\n",
        "  - https://github.com/tensorflow/models/blob/master/research/slim/nets/vgg.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87jIPIOOSlPo"
      },
      "source": [
        "## 케라스 모델\n",
        "\n",
        "- 케라스 API에서 공식적으로 제공\n",
        "\n",
        "  - `tf.keras.applications` 패키지를 통해 접근 가능\n",
        "\n",
        "  - 해당 패키지는 사전 훈련된 매개변수도 제공"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Ea52RHRWjSAs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45PZwVLSTg4m"
      },
      "source": [
        "- 사용 예시\n",
        "  - ImageNet에서 훈련이 끝난 후 얻게된 매개변수 값 로딩\n",
        "\n",
        "  - 만약, 네트워크를 다시 처음부터 학습하고자 한다면 `weights=None`으로 설정.  \n",
        "    케라스에서 무작위로 가중치를 설정함\n",
        "\n",
        "  - `include_top=False` : VGG의 밀집 계층을 제외한다는 뜻\n",
        "    \n",
        "    - 해당 네트워크의 출력은 합성곱/최대-풀링 블록의 특징맵이 됨\n",
        "\n",
        "  - `pooling` : 특징맵을 반환하기 전에 적용할 선택적인 연산을 지정  \n",
        "    \n",
        "    ex) `pooling='avg'` 또는 `pooling='max'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "m1mnnxcilbdr"
      },
      "outputs": [],
      "source": [
        "vgg_net = tf.keras.applications.VGG16(include_top=True, weights='imagenet',\n",
        "                                      input_tensor=None, input_shape=None,\n",
        "                                      pooling=None, classes=1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138357544 (527.79 MB)\n",
            "Trainable params: 138357544 (527.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "fmQm2hVmUtD4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 19s 0us/step\n",
            "Epoch 1/20\n",
            "234/782 [=======>......................] - ETA: 17:07 - loss: 2.3030 - accuracy: 0.1029"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[62], line 68\u001b[0m\n\u001b[1;32m     63\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     64\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     65\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, \n\u001b[1;32m     69\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, \n\u001b[1;32m     70\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[1;32m     71\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test))\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
            "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터셋 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# VGG-16 모델 클래스 정의\n",
        "class VGG16(Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(VGG16, self).__init__()\n",
        "        # 1~2단계 합성곱과 풀링\n",
        "        self.conv1_1 = Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv1_2 = Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.pool1 = MaxPooling2D((2, 2), strides=(2, 2))\n",
        "\n",
        "        # 3~4단계 합성곱과 풀링\n",
        "        self.conv2_1 = Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv2_2 = Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.pool2 = MaxPooling2D((2, 2), strides=(2, 2))\n",
        "\n",
        "        # 5~7단계 합성곱과 풀링\n",
        "        self.conv3_1 = Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv3_2 = Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv3_3 = Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.pool3 = MaxPooling2D((2, 2), strides=(2, 2))\n",
        "\n",
        "        # 8~10단계 합성곱과 풀링\n",
        "        self.conv4_1 = Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv4_2 = Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv4_3 = Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.pool4 = MaxPooling2D((2, 2), strides=(2, 2))\n",
        "\n",
        "        # 11~13단계 합성곱과 풀링\n",
        "        self.conv5_1 = Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv5_2 = Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv5_3 = Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.pool5 = MaxPooling2D((2, 2), strides=(2, 2))\n",
        "\n",
        "        # 완전 연결 레이어\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(4096, activation='relu')\n",
        "        self.fc2 = Dense(4096, activation='relu')\n",
        "        self.output_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.pool1(self.conv1_2(self.conv1_1(inputs)))\n",
        "        x = self.pool2(self.conv2_2(self.conv2_1(x)))\n",
        "        x = self.pool3(self.conv3_3(self.conv3_2(self.conv3_1(x))))\n",
        "        x = self.pool4(self.conv4_3(self.conv4_2(self.conv4_1(x))))\n",
        "        x = self.pool5(self.conv5_3(self.conv5_2(self.conv5_1(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc2(self.fc1(x))\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# 하이퍼파라미터 설정 및 모델 컴파일\n",
        "num_classes = 10\n",
        "model = VGG16(num_classes)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, \n",
        "          batch_size=64, \n",
        "          epochs=20, \n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKkQqFUUVtP"
      },
      "source": [
        "# GoogLeNet, Inception 모듈\n",
        "\n",
        "- VGGNet을 제치고 같은 해 분류 과제에서 1등을 차지\n",
        "\n",
        "- 인셉션 블록이라는 개념을 도입하여, **인셉션 네트워크(Inception Network)**라고도 불림\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/2800/0*rbWRzjKvoGt9W3Mf.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5</sub>\n",
        "\n",
        "  <br>\n",
        "\n",
        "- 특징\n",
        "  \n",
        "  - CNN 계산 용량을 최적화하는 것을 고려\n",
        "\n",
        "  - 전형적인 합성곱, 풀링 계층으로 시작하고, 이 정보는 9개의 인셉션 모듈 스택을 통과  \n",
        "    해당 모듈을 하위 네트워크라고도 함\n",
        "\n",
        "  - 각 모듈에서 입력 특징 맵은 서로 다른 계층으로 구성된 4개의 병렬 하위 블록에 전달되고, 이를 서로 다시 연결\n",
        "\n",
        "  - 모든 합성곱과 풀링 계층의 padding옵션은 \"SAME\"이며 `stride=1`,  \n",
        "    활성화 함수는 `ReLU` 사용\n",
        "\n",
        "- 기여\n",
        "\n",
        "  - 규모가 큰 블록과 병목을 보편화\n",
        "\n",
        "  - 병목 계층으로 1x1 합성곱 계층 사용\n",
        "\n",
        "  - 완전 연결 계층 대신 풀링 계층 사용\n",
        "\n",
        "  - 중간 소실로 경사 소실 문제 해결\n",
        "\n",
        "  <img src=\"https://norman3.github.io/papers/images/google_inception/f01.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://norman3.github.io/papers/docs/google_inception.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okr3BazPYOpK"
      },
      "source": [
        "## 케라스로 Inception 모듈 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "SkrjUxOGTo-b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BajRJH3jYvLH"
      },
      "source": [
        "- 임의의 input_shape 값 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4NQ-_jViYtxd"
      },
      "outputs": [],
      "source": [
        "input_shape=(28, 28, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjf6NlAeYe5b"
      },
      "source": [
        "- 순차형 API 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "v8NSAg5tYauB"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5,5), input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "HXM4AD1WZDO2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 24, 24, 32)        2432      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 12, 12, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                46090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48522 (189.54 KB)\n",
            "Trainable params: 48522 (189.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Xpkz1JZGcv"
      },
      "source": [
        "- 함수형 API 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "6R3LlxrXZEFJ"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    inputs = Input(shape=input_shape)\n",
        "    conv1 = Conv2D(32, kernel_size(5,5))(inputs)\n",
        "    maxpool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
        "    predictions = Dense(10, activation='softmax')(Flatten()(maxpool1))\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Bex7TSZgaN"
      },
      "source": [
        "- 원시 버전의 인셉션 블록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "eVnpgzB4ZcSD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "RWgx32AvZnwm"
      },
      "outputs": [],
      "source": [
        "def naive_inception_block(prev_layer, filters=[64, 128, 32]):\n",
        "    conv1x1 = Conv2D(filters[0], kernel_size=(1,1), padding='same', activation='relu')(prev_layer)\n",
        "    conv3x3 = Conv2D(filters[1], kernel_size=(3,3), padding='same', activation='relu')(prev_layer)\n",
        "    conv5x5 = Conv2D(filters[2], kernel_size=(5,5), padding='same', activation='relu')(prev_layer)\n",
        "    max_pool = MaxPool2D((3,3), strides=(1,1), padding='same')(prev_layer)\n",
        "\n",
        "    return concatenate([conv1x1, conv3x3, conv5x5, max_pool], axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm4_bmSmaaV9"
      },
      "source": [
        "## 케라스 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "FcLK4rlSZ1pj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96112376/96112376 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "inceptionV3_net = tf.keras.applications.InceptionV3(\n",
        "    include_top = True, weights='imagenet', input_tensor=None, input_shape=None,\n",
        "    pooling=None, classes=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "m_ryx4HCaoxA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 299, 299, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 149, 149, 32)         864       ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 149, 149, 32)         96        ['conv2d_13[0][0]']           \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 149, 149, 32)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 147, 147, 32)         9216      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 147, 147, 32)         96        ['conv2d_14[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 147, 147, 32)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 147, 147, 64)         18432     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 147, 147, 64)         192       ['conv2d_15[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 147, 147, 64)         0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 73, 73, 64)           0         ['activation_2[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 73, 73, 80)           5120      ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 73, 73, 80)           240       ['conv2d_16[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 73, 73, 80)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 71, 71, 192)          138240    ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 71, 71, 192)          576       ['conv2d_17[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 71, 71, 192)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 35, 35, 192)          0         ['activation_4[0][0]']        \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 35, 35, 64)           12288     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 35, 35, 64)           192       ['conv2d_21[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 35, 35, 48)           9216      ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 35, 35, 48)           144       ['conv2d_19[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 35, 35, 96)           288       ['conv2d_22[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 35, 35, 48)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 35, 35, 96)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (Avera  (None, 35, 35, 192)          0         ['max_pooling2d_10[0][0]']    \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 35, 35, 64)           12288     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 35, 35, 32)           6144      ['average_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 35, 35, 64)           192       ['conv2d_18[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 35, 35, 64)           192       ['conv2d_20[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 35, 35, 96)           288       ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 35, 35, 32)           96        ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 35, 35, 32)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 35, 35, 256)          0         ['activation_5[0][0]',        \n",
            "                                                                     'activation_7[0][0]',        \n",
            "                                                                     'activation_10[0][0]',       \n",
            "                                                                     'activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 35, 35, 64)           192       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 35, 35, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 35, 35, 48)           144       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 35, 35, 96)           288       ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 35, 35, 48)           0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (Avera  (None, 35, 35, 256)          0         ['mixed0[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 35, 35, 64)           16384     ['average_pooling2d_3[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 35, 35, 64)           192       ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 35, 35, 64)           192       ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 35, 35, 96)           288       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 35, 35, 64)           192       ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 35, 35, 288)          0         ['activation_12[0][0]',       \n",
            "                                                                     'activation_14[0][0]',       \n",
            "                                                                     'activation_17[0][0]',       \n",
            "                                                                     'activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 35, 35, 64)           192       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 35, 35, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 35, 35, 48)           144       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 35, 35, 96)           288       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 35, 35, 48)           0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (Avera  (None, 35, 35, 288)          0         ['mixed1[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 35, 35, 64)           18432     ['average_pooling2d_4[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 35, 35, 64)           192       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 35, 35, 64)           192       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 35, 35, 96)           288       ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 35, 35, 64)           192       ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 35, 35, 288)          0         ['activation_19[0][0]',       \n",
            "                                                                     'activation_21[0][0]',       \n",
            "                                                                     'activation_24[0][0]',       \n",
            "                                                                     'activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 35, 35, 64)           192       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 35, 35, 96)           288       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 17, 17, 384)          995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 17, 17, 96)           82944     ['activation_28[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 17, 17, 384)          1152      ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 17, 17, 96)           288       ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 17, 17, 384)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 17, 17, 96)           0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 17, 17, 288)          0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 17, 17, 768)          0         ['activation_26[0][0]',       \n",
            "                                                                     'activation_29[0][0]',       \n",
            "                                                                     'max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 17, 17, 128)          384       ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 17, 17, 128)          384       ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 17, 17, 128)          384       ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 17, 17, 128)          384       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 17, 17, 128)          384       ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 17, 17, 128)          384       ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (Avera  (None, 17, 17, 768)          0         ['mixed3[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 17, 17, 192)          172032    ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 17, 17, 192)          172032    ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_5[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 17, 17, 192)          576       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 17, 17, 192)          576       ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 17, 17, 192)          576       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 17, 17, 192)          576       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 17, 17, 768)          0         ['activation_30[0][0]',       \n",
            "                                                                     'activation_33[0][0]',       \n",
            "                                                                     'activation_38[0][0]',       \n",
            "                                                                     'activation_39[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 17, 17, 160)          480       ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 17, 17, 160)          480       ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 17, 17, 160)          480       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 17, 17, 160)          480       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 17, 17, 160)          480       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 17, 17, 160)          480       ['conv2d_60[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (Avera  (None, 17, 17, 768)          0         ['mixed4[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_42[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_47[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_6[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 17, 17, 192)          576       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 17, 17, 192)          576       ['conv2d_56[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 17, 17, 192)          576       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 17, 17, 192)          576       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 17, 17, 768)          0         ['activation_40[0][0]',       \n",
            "                                                                     'activation_43[0][0]',       \n",
            "                                                                     'activation_48[0][0]',       \n",
            "                                                                     'activation_49[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 17, 17, 160)          480       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_54[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 17, 17, 160)          480       ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 17, 17, 160)          480       ['conv2d_64[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 17, 17, 160)          480       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 17, 17, 160)          480       ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 17, 17, 160)          480       ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (Avera  (None, 17, 17, 768)          0         ['mixed5[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_52[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_57[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_7[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 17, 17, 192)          576       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 17, 17, 192)          576       ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 17, 17, 192)          576       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 17, 17, 192)          576       ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 17, 17, 768)          0         ['activation_50[0][0]',       \n",
            "                                                                     'activation_53[0][0]',       \n",
            "                                                                     'activation_58[0][0]',       \n",
            "                                                                     'activation_59[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 17, 17, 192)          576       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 17, 17, 192)          576       ['conv2d_78[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 17, 17, 192)          576       ['conv2d_74[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 17, 17, 192)          576       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 17, 17, 192)          576       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 17, 17, 192)          576       ['conv2d_80[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (Avera  (None, 17, 17, 768)          0         ['mixed6[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_67[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_8[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 17, 17, 192)          576       ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 17, 17, 192)          576       ['conv2d_76[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 17, 17, 192)          576       ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 17, 17, 192)          576       ['conv2d_82[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 17, 17, 768)          0         ['activation_60[0][0]',       \n",
            "                                                                     'activation_63[0][0]',       \n",
            "                                                                     'activation_68[0][0]',       \n",
            "                                                                     'activation_69[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 17, 17, 192)          576       ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_72[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 17, 17, 192)          576       ['conv2d_86[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 17, 17, 192)          576       ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 17, 17, 192)          576       ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 8, 8, 320)            552960    ['activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 8, 8, 192)            331776    ['activation_74[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 8, 8, 320)            960       ['conv2d_84[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 8, 8, 192)            576       ['conv2d_88[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooli  (None, 8, 8, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 8, 8, 1280)           0         ['activation_71[0][0]',       \n",
            "                                                                     'activation_75[0][0]',       \n",
            "                                                                     'max_pooling2d_12[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 8, 8, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 8, 8, 448)            1344      ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 8, 8, 448)            0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 8, 8, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 8, 8, 384)            1548288   ['activation_80[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 8, 8, 384)            1152      ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 8, 8, 384)            1152      ['conv2d_94[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_77[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_9 (Avera  (None, 8, 8, 1280)           0         ['mixed8[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 8, 8, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 8, 8, 384)            1152      ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 8, 8, 384)            1152      ['conv2d_92[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 8, 8, 384)            1152      ['conv2d_95[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 8, 8, 384)            1152      ['conv2d_96[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 8, 8, 192)            245760    ['average_pooling2d_9[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 8, 8, 320)            960       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_82 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_83 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 8, 8, 192)            576       ['conv2d_97[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 8, 8, 768)            0         ['activation_78[0][0]',       \n",
            "                                                                     'activation_79[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8, 8, 768)            0         ['activation_82[0][0]',       \n",
            "                                                                     'activation_83[0][0]']       \n",
            "                                                                                                  \n",
            " activation_84 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 8, 8, 2048)           0         ['activation_76[0][0]',       \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate[0][0]',         \n",
            "                                                                     'activation_84[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)         (None, 8, 8, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 8, 8, 448)            1344      ['conv2d_102[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_89 (Activation)  (None, 8, 8, 448)            0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)          (None, 8, 8, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)         (None, 8, 8, 384)            1548288   ['activation_89[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 8, 8, 384)            1152      ['conv2d_99[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 8, 8, 384)            1152      ['conv2d_103[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_86 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_90 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)         (None, 8, 8, 384)            442368    ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_10 (Aver  (None, 8, 8, 2048)           0         ['mixed9[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 8, 8, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 8, 8, 384)            1152      ['conv2d_100[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 8, 8, 384)            1152      ['conv2d_101[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 8, 8, 384)            1152      ['conv2d_104[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 8, 8, 384)            1152      ['conv2d_105[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)         (None, 8, 8, 192)            393216    ['average_pooling2d_10[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 8, 8, 320)            960       ['conv2d_98[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_87 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_88 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_91 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_92 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 8, 8, 192)            576       ['conv2d_106[0][0]']          \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 8, 8, 768)            0         ['activation_87[0][0]',       \n",
            "                                                                     'activation_88[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 8, 8, 768)            0         ['activation_91[0][0]',       \n",
            " )                                                                   'activation_92[0][0]']       \n",
            "                                                                                                  \n",
            " activation_93 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 8, 8, 2048)           0         ['activation_85[0][0]',       \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_1[0][0]',       \n",
            "                                                                     'activation_93[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['mixed10[0][0]']             \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 2049000   ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23851784 (90.99 MB)\n",
            "Trainable params: 23817352 (90.86 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inceptionV3_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def googlenet(input_shape=(32, 32, 3), num_classes=10):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    \n",
        "    # 초기 합성곱 및 풀링 레이어\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    # Inception 모듈 쌓기\n",
        "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
        "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
        "    x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
        "    x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
        "    x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
        "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    # 마지막 Inception 모듈들\n",
        "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
        "    x = inception_module(x, 384, 192, 384, 48, 128, 128)\n",
        "    \n",
        "    # 완전 연결 레이어\n",
        "    x = AveragePooling2D((4, 4), padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(input_layer, x, name='GoogLeNet')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P91oc7YFauuk"
      },
      "source": [
        "# ResNet - 잔차 네트워크\n",
        "\n",
        "- 네트워크의 깊이가 깊어질수록 경사가 소실되거나 폭발하는 문제를 해결하고자 함\n",
        "\n",
        "- 병목 합성곱 계층을 추가하거나 크기가 작은 커널을 사용\n",
        "\n",
        "- 152개의 훈련가능한 계층을 수직으로 연결하여 구성\n",
        "\n",
        "- 모든 합성곱과 풀링 계층에서 패딩옵셥으로 \"SAME\", stride=1 사용\n",
        "\n",
        "- 3x3 합성곱 계층 다음마다 배치 정규화 적용,  \n",
        "  1x1 합성곱 계층에는 활성화 함수가 존재하지 않음\n",
        "\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/1200/1*6hF97Upuqg_LdsqWY6n_wg.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIix2vrbwH9"
      },
      "source": [
        "## 잔차 블록 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "0SBaUMSfaqgH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Activation, Conv2D, BatchNormalization, add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "9da3RqU_c4MZ"
      },
      "outputs": [],
      "source": [
        "def residual_block_basic(x, filters, kernel_size=3, strides=1):\n",
        "    conv_1 = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                    padding='same', strides=strides(x))\n",
        "    bn_1 = BatchNormalization(axis=1)(conv_1)\n",
        "    act_1 = Activation('relu')(bn_1)\n",
        "    conv_2 = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                    padding='same', strides=strides)(act_1)\n",
        "    residual = BatchNormalization(axis=-1)(conv_2)\n",
        "\n",
        "    shortcut = x if strides == 1 else Conv2D(filters, kerenl_size=1, padding='valid', strides=strides)(x)\n",
        "\n",
        "    return Activation('relu')(add([shortcut, residual]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1qyz3Jcds9Y"
      },
      "source": [
        "## 케라스 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "b6UTGl44drbG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet50 = tf.keras.applications.ResNet50(\n",
        "    include_top=True, weights='imagenet',\n",
        "    input_tensor=None, input_shape=None,\n",
        "    pooling=None, classes=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "nCETH9aZd0V3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n",
            "                                                                     'conv4_block6_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n",
            "                                                                     'conv5_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
            "                                                                     'conv5_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
            "                                                                     'conv5_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " predictions (Dense)         (None, 1000)                 2049000   ['avg_pool[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25636712 (97.80 MB)\n",
            "Trainable params: 25583592 (97.59 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet50.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def residual_block(x, filters, kernel_size=3, stride=1):\n",
        "    # 잔차 연결에 사용될 입력\n",
        "    shortcut = x\n",
        "\n",
        "    # 첫 번째 합성곱 레이어\n",
        "    x = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # 두 번째 합성곱 레이어\n",
        "    x = layers.Conv2D(filters, kernel_size=kernel_size, padding='same', activation=None)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # 스킵 연결이 필요할 경우 (stride가 1이 아닐 때)\n",
        "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
        "        shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    # 스킵 연결 수행\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def ResNet(input_shape=(32, 32, 3), num_classes=10):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # 초기 합성곱 레이어\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Residual Block 스택 생성\n",
        "    x = residual_block(x, filters=64, stride=1)\n",
        "    x = residual_block(x, filters=64, stride=1)\n",
        "\n",
        "    x = residual_block(x, filters=128, stride=2)  # 공간 크기 감소\n",
        "    x = residual_block(x, filters=128, stride=1)\n",
        "\n",
        "    x = residual_block(x, filters=256, stride=2)\n",
        "    x = residual_block(x, filters=256, stride=1)\n",
        "\n",
        "    x = residual_block(x, filters=512, stride=2)\n",
        "    x = residual_block(x, filters=512, stride=1)\n",
        "\n",
        "    # 출력 레이어\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(input_layer, x, name=\"ResNet\")\n",
        "    return model\n",
        "    \n",
        "# CIFAR-10 데이터셋 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 모델 생성 및 컴파일\n",
        "model = ResNet(input_shape=(32, 32, 3), num_classes=10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
